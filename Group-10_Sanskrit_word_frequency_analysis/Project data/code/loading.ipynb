{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up WebDriver (e.g., Chrome)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the website\n",
    "driver.get(\"http://www.sanskrit-linguistics.org/dcs/index.php?contents=texte\")  \n",
    "\n",
    "# Wait for the text box containing the book names to load\n",
    "wait = WebDriverWait(driver, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chapter(book_info, chapter_container, chapter_name):\n",
    "    chapter_option = chapter_container.find_elements(By.XPATH, f\".//option[contains(text(), '{chapter_name}')]\")\n",
    "    chapter_option[0].click()\n",
    "    \n",
    "    attempts_remaining = 25\n",
    "    while attempts_remaining:\n",
    "        try:\n",
    "            \n",
    "            time.sleep(1)\n",
    "            sentence_container = wait.until(EC.presence_of_element_located((By.ID, \"sentences\")))\n",
    "            wait.until(lambda driver: len(driver.find_elements(By.XPATH, '//*[@id=\"sentences\"]/div[contains(@class, \"sentence_div\") or contains(@class, \"sentence_analysis_div\")]')) > 0)\n",
    "            combined_list = [element for element in driver.find_elements(By.XPATH, '//*[@id=\"sentences\"]/div[contains(@class, \"sentence_div\") or contains(@class, \"sentence_analysis_div\")]')]\n",
    "            working_pair_list = []\n",
    "            pair = []\n",
    "            for element in combined_list:\n",
    "                if(element.get_attribute(\"class\") == \"sentence_div\" and len(pair)>0):\n",
    "                    working_pair_list.append(pair)\n",
    "                    pair = []            \n",
    "                pair.append(element)\n",
    "            if(len(pair)>0):\n",
    "                working_pair_list.append(pair)\n",
    "            for _pair in working_pair_list:\n",
    "                element_dict = dict()\n",
    "                sentenceHTML = _pair[0].get_attribute(\"innerHTML\")\n",
    "                sentence = sentenceHTML[sentenceHTML.find('\\\\') + 2 : sentenceHTML.find('/')]\n",
    "                a_lists = _pair[1].find_elements(By.CLASS_NAME, 'text-lemma-link')\n",
    "                a_texts = [a.get_attribute(\"innerHTML\") for a in a_lists]\n",
    "                element_dict['text'] = sentence\n",
    "                element_dict['root_words'] = a_texts\n",
    "                book_info['lines'].append(element_dict)\n",
    "                \n",
    "\n",
    "\n",
    "            return 1\n",
    "        except StaleElementReferenceException:\n",
    "            attempts_remaining -= 1\n",
    "            print(f\"Stale element reference while loading {chapter_name}. Retrying...\")\n",
    "            time.sleep(1)\n",
    "    if attempts_remaining == 0:\n",
    "        print(f\"{chapter_name} of {book_info['name']} could not be loaded.\")\n",
    "        return 0\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chapter2(book_info, chapter_name):\n",
    "    \n",
    "    attempts_remaining = 25\n",
    "    while attempts_remaining:\n",
    "        try:\n",
    "            \n",
    "            time.sleep(1)\n",
    "            sentence_container = wait.until(EC.presence_of_element_located((By.ID, \"sentences\")))\n",
    "            wait.until(lambda driver: len(driver.find_elements(By.XPATH, '//*[@id=\"sentences\"]/div[contains(@class, \"sentence_div\") or contains(@class, \"sentence_analysis_div\")]')) > 0)\n",
    "            combined_list = [element for element in driver.find_elements(By.XPATH, '//*[@id=\"sentences\"]/div[contains(@class, \"sentence_div\") or contains(@class, \"sentence_analysis_div\")]')]\n",
    "            working_pair_list = []\n",
    "            pair = []\n",
    "            for element in combined_list:\n",
    "                if(element.get_attribute(\"class\") == \"sentence_div\" and len(pair)>0):\n",
    "                    working_pair_list.append(pair)\n",
    "                    pair = []            \n",
    "                pair.append(element)\n",
    "            if(len(pair)>0):\n",
    "                working_pair_list.append(pair)\n",
    "            for _pair in working_pair_list:\n",
    "                element_dict = dict()\n",
    "                sentenceHTML = _pair[0].get_attribute(\"innerHTML\")\n",
    "                sentence = sentenceHTML[sentenceHTML.find('\\\\') + 2 : sentenceHTML.find('/')]\n",
    "                a_lists = _pair[1].find_elements(By.CLASS_NAME, 'text-lemma-link')\n",
    "                a_texts = [a.get_attribute(\"innerHTML\") for a in a_lists]\n",
    "                element_dict['text'] = sentence\n",
    "                element_dict['root_words'] = a_texts\n",
    "                book_info['lines'].append(element_dict)\n",
    "                \n",
    "\n",
    "\n",
    "            return 1\n",
    "        except StaleElementReferenceException:\n",
    "            attempts_remaining -= 1\n",
    "            print(f\"Stale element reference while loading {chapter_name}. Retrying...\")\n",
    "            time.sleep(1)\n",
    "    if attempts_remaining == 0:\n",
    "        print(f\"{chapter_name} of {book_info['name']} could not be loaded.\")\n",
    "        return 0\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_book(book_container, book_name):\n",
    "    book_option = book_container.find_element(By.XPATH, f'.//option[contains(text(), \"{book_name}\")]')\n",
    "    book_option.click()\n",
    "\n",
    "    max_attempts = 5\n",
    "    attempt = 0 \n",
    "    # Wait for the text box containing the book names to load\n",
    "    wait = WebDriverWait(driver, 20)\n",
    "    \n",
    "    book_info = {}\n",
    "    book_info['name'] = book_name\n",
    "    book_info['time'] = \"\"\n",
    "    unloaded_chapter_exists = False\n",
    "\n",
    "    while attempt < max_attempts:\n",
    "        try:\n",
    "            book_info['lines'] = []\n",
    "            status = process_chapter2(book_info=book_info, chapter_name=book_name)\n",
    "            if status == 0:\n",
    "                unloaded_chapter_exists = True\n",
    "                break\n",
    "            # chapter_container = wait.until(EC.presence_of_element_located((By.ID, \"chapter_id\"))) \n",
    "            # wait.until(lambda driver: len(driver.find_elements(By.XPATH, '//*[@id=\"chapter_id\"]/option')) > 0)\n",
    "            # chapter_list = [chapter.text for chapter in driver.find_elements(By.XPATH, '//*[@id=\"chapter_id\"]/option')] # <--- list of all chapters in that book\n",
    "            # for chapter in chapter_list:\n",
    "                # print(chapter)\n",
    "                # status = process_chapter(book_info, chapter_container=chapter_container, chapter_name=chapter)\n",
    "            if unloaded_chapter_exists:\n",
    "                attempt += 1\n",
    "                print(\"A chapter couldn't be loaded after multiple retries. Reloading the whole book...\")\n",
    "                continue\n",
    "            else:\n",
    "                cleaned_book_name = re.sub(r\"\\?\", \"\", book_info['name'])\n",
    "                with open(f\"{cleaned_book_name}.json\",'w') as json_file:\n",
    "                    json.dump(book_info, json_file, indent=4)\n",
    "                return 1\n",
    "        except StaleElementReferenceException:\n",
    "            attempt += 1\n",
    "            print(attempt)\n",
    "            print(f\"Stale element reference while loading {book_name}. Retrying...\")\n",
    "            time.sleep(1)\n",
    "\n",
    "    if attempt == max_attempts:\n",
    "        print(\"Failed to locate the element after multiple attempts.\")\n",
    "    if unloaded_chapter_exists:\n",
    "        print(f\"book {book_info['name']} couldn't be fully loaded after multiple attempts.\")\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the text box or dropdown that contains the book names\n",
    "book_container = wait.until(EC.presence_of_element_located((By.ID, \"text_id\")))  # replace with the actual ID or locator\n",
    "\n",
    "\n",
    "book_list = [book.text for book in driver.find_elements(By.XPATH, '//*[@id=\"text_id\"]/option')] # <--- LIST OF ALL BOOKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_set = set(book_list)\n",
    "l_book = set()\n",
    "doc_list = [f for f in os.listdir() if (f.endswith('.json') and f != 'sanskrit_dict.json')]\n",
    "for doc in doc_list:\n",
    "    with open(doc, 'r') as book:\n",
    "        book_info = json.load(book)  \n",
    "        l_book.add(book_info['name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unloaded_books = list(book_set.difference(l_book))\n",
    "unloaded_books.remove(\"AMTest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "incomplete_loads = []\n",
    "for book_name in unloaded_books:\n",
    "    book_status = process_book(book_container=book_container, book_name=book_name)\n",
    "    if book_status == 0:\n",
    "        incomplete_loads.append(book_name)\n",
    "\n",
    "if(len(incomplete_loads)):\n",
    "    print(\"Books that didn't load completely:\")\n",
    "    for book in incomplete_loads:\n",
    "        print(book)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_list.index(\"Śira'upaniṣad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kaulāvalīnirṇaya', 'Kāvyasaṃgraha', 'Āyaraṅga', 'Nyāyacandrikāpaṇjikā', 'G\\ufff8ḍhārthaprakāśaka', 'Paṃcasuttaṃ', 'Rasaratnākara Rasakhaṇḍa', 'Rasaratnākara', 'Pavanadūta']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
